{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten digits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehEOQwOGVF8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torchvision.datasets as dsets \n",
        "import torchvision.transforms as transforms \n",
        "from torch.autograd import Variable "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tv98PwyVlm9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8i6YG5_VmFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining hyper parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# MNIST Dataset (Images and Labels) \n",
        "train_dataset = dsets.MNIST(root ='./data', \n",
        "\t\t\t\t\t\t\ttrain = True, \n",
        "\t\t\t\t\t\t\ttransform = transforms.ToTensor(), \n",
        "\t\t\t\t\t\t\tdownload = True) \n",
        "\n",
        "test_dataset = dsets.MNIST(root ='./data', \n",
        "\t\t\t\t\t\ttrain = False, \n",
        "\t\t\t\t\t\ttransform = transforms.ToTensor()) \n",
        "\n",
        "# Dataset Loader (Input Pipline) \n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = True) \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size, \n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw8nDBhIV4Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(nn.Module): \n",
        "\tdef __init__(self, input_size, num_classes): \n",
        "\t\tsuper(LogisticRegression, self).__init__() \n",
        "\t\tself.linear = nn.Linear(input_size, num_classes) \n",
        "\n",
        "\tdef forward(self, x): \n",
        "\t\tout = self.linear(x) \n",
        "\t\treturn out "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1XexK60V7WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LogisticRegression(input_size, num_classes) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT7dgvOYV_LE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKtPaoQWALs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "085ea233-a589-4805-df3f-aa8cfd9b9901"
      },
      "source": [
        "# Training the Model \n",
        "for epoch in range(num_epochs): \n",
        "\tfor i, (images, labels) in enumerate(train_loader): \n",
        "\t\timages = Variable(images.view(-1, 28 * 28)) \n",
        "\t\tlabels = Variable(labels) \n",
        "\n",
        "\t\t# Forward + Backward + Optimize \n",
        "\t\toptimizer.zero_grad() \n",
        "\t\toutputs = model(images) \n",
        "\t\tloss = criterion(outputs, labels) \n",
        "\t\tloss.backward() \n",
        "\t\toptimizer.step() \n",
        "\n",
        "\t\tif (i + 1) % 100 == 0: \n",
        "\t\t\tprint('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "\t\t\t\t% (epoch + 1, num_epochs, i + 1, (len(train_dataset) // batch_size), loss.data)) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.0089\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 1.9137\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 1.8221\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.7342\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.7147\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.6643\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.6631\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.5479\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.4504\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.4370\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.4498\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.3182\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.3361\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3183\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.2354\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2576\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.1566\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2128\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.1204\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1375\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.0650\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.0453\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.0270\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0687\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.0448\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0006\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.0986\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 0.9612\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.9815\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.1406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0GX7myGWE9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42f0b348-cc22-48d2-fb6b-9929c692dae4"
      },
      "source": [
        "# Test the Model \n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader: \n",
        "\timages = Variable(images.view(-1, 28 * 28)) \n",
        "\toutputs = model(images) \n",
        "\t_, predicted = torch.max(outputs.data, 1) \n",
        "\ttotal += labels.size(0) \n",
        "\tcorrect += (predicted == labels).sum() \n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % ( \n",
        "\t\t\t100 * correct / total)) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images:  83 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}